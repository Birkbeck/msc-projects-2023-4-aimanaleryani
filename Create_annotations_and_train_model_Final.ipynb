{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0aBi5Pl9wMC"
      },
      "outputs": [],
      "source": [
<<<<<<< HEAD
=======
        "# Install detectron2\n",
        "\n",
        "# # First, check the CUDA version\n",
        "# !nvcc --version\n",
        "\n",
        "# # Install torch and torchvision\n",
        "# import torch\n",
        "# print(torch.__version__)  # Check the PyTorch version\n",
        "\n",
        "# # Installation command for Detectron2 compatible with the CUDA version\n",
        "# # The CUDA version in your output helps determine the right torch and torchvision versions\n",
        "# # Assuming CUDA 10.1, which is common in Colab, but check your specific version\n",
        "\n",
        "# # Uninstall existing PyTorch and torchvision before installing the correct version\n",
        "# !pip uninstall -y torch torchvision\n",
        "# !pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# # Install Detectron2\n",
        "# !pip install detectron2 -f \\\n",
        "#   https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0aBi5Pl9wMC"
      },
      "outputs": [],
      "source": [
>>>>>>> 158534d6aaedb57b618a3942cff5ec0c915b0143
        "!nvcc --version\n",
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tJlkDJBm-Dng"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Install Detectron2 from the source\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBYvyaY-pcNq"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.structures import BoxMode\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddtWV4XKqXau"
      },
      "source": [
        "## 1. resize images and create COCO annotations json file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8VYQFSPqGjO"
      },
      "outputs": [],
      "source": [
        "#Set up directory and mounting from GDrive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Project/Kaggle/Water bodies resized/')\n",
        "\n",
        "#DATASET https://www.kaggle.com/datasets/franciscoescobar/satellite-images-of-water-bodies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-yEkoetMukQC"
      },
      "outputs": [],
      "source": [
        "#we need to resize images before creating annotated dataset so that the annotations contain the correct dimensions\n",
        "\n",
        "# from PIL import Image\n",
        "\n",
        "# def resize_image_and_mask(image_dir, mask_dir, output_image_dir, output_mask_dir, new_size):\n",
        "#     # Create output directories if they don't exist\n",
        "#     os.makedirs(output_image_dir, exist_ok=True)\n",
        "#     os.makedirs(output_mask_dir, exist_ok=True)\n",
        "\n",
        "#     # List all images in the image directory\n",
        "#     image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "#     for image_file in image_files:\n",
        "#         # Define the full path to the image and mask files\n",
        "#         image_path = os.path.join(image_dir, image_file)\n",
        "#         mask_path = os.path.join(mask_dir, image_file)  # Assuming mask has same filename as image\n",
        "\n",
        "#         # Read the image and mask using OpenCV\n",
        "#         image = cv2.imread(image_path)\n",
        "#         mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Read the mask in grayscale\n",
        "\n",
        "#         if image is None or mask is None:\n",
        "#             print(f\"Error reading file {image_file}, skipping...\")\n",
        "#             continue\n",
        "\n",
        "#         # Resize the image and mask\n",
        "#         resized_image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
        "#         resized_mask = cv2.resize(mask, new_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "#         # Define the output paths\n",
        "#         output_image_path = os.path.join(output_image_dir, image_file)\n",
        "#         output_mask_path = os.path.join(output_mask_dir, image_file)\n",
        "\n",
        "#         # Save the resized image and mask\n",
        "#         cv2.imwrite(output_image_path, resized_image)\n",
        "#         cv2.imwrite(output_mask_path, resized_mask)\n",
        "\n",
        "#         print(f\"Processed and saved: {image_file}\")\n",
        "\n",
        "# # Configuration\n",
        "# image_dir = '/content/drive/MyDrive/Project/Kaggle/Water Bodies Dataset/Images/'\n",
        "# mask_dir = '/content/drive/MyDrive/Project/Kaggle/Water Bodies Dataset/Masks/'\n",
        "# output_image_dir = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/images/'\n",
        "# output_mask_dir = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/masks/'\n",
        "# new_size = (512, 512)  # New width and height as per paper\n",
        "\n",
        "# # Process all images and masks\n",
        "# resize_image_and_mask(image_dir, mask_dir, output_image_dir, output_mask_dir, new_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyoRR7ttwqYj"
      },
      "outputs": [],
      "source": [
        "#Attempt 2\n",
        "###FROM: https://github.com/waspinator/pycococreator/blob/master/pycococreatortools/pycococreatortools.py\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "from itertools import groupby\n",
        "from skimage import measure\n",
        "from skimage.io import imread\n",
        "from PIL import Image\n",
        "from pycocotools import mask\n",
        "from pycocotools import mask as coco_mask\n",
        "\n",
        "# Paths to images and masks\n",
        "images_path = \"/content/drive/MyDrive/Project/Kaggle/Water bodies resized/images/\"\n",
        "masks_path = \"/content/drive/MyDrive/Project/Kaggle/Water bodies resized/masks/\"\n",
        "\n",
        "convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "natural_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
        "\n",
        "def resize_binary_mask(array, new_size):\n",
        "    image = Image.fromarray(array.astype(np.uint8)*255)\n",
        "    image = image.resize(new_size, Image.NEAREST)\n",
        "    return np.asarray(image).astype(np.bool_)\n",
        "\n",
        "def close_contour(contour):\n",
        "    if not np.array_equal(contour[0], contour[-1]):\n",
        "        contour = np.vstack((contour, contour[0]))\n",
        "    return contour\n",
        "\n",
        "def binary_mask_to_polygon(binary_mask, tolerance=0):\n",
        "    polygons = []\n",
        "    padded_binary_mask = np.pad(binary_mask, pad_width=1, mode='constant', constant_values=0)\n",
        "    contours = measure.find_contours(padded_binary_mask, 0.5)\n",
        "\n",
        "    for contour in contours:\n",
        "        # Subtract 1 from each contour point\n",
        "        contour = contour - 1  # This operates element-wise on the numpy array\n",
        "\n",
        "        contour = close_contour(contour)\n",
        "        contour = measure.approximate_polygon(contour, tolerance)\n",
        "        if len(contour) < 3:\n",
        "            continue\n",
        "        contour = np.flip(contour, axis=1)\n",
        "        segmentation = contour.ravel().tolist()\n",
        "        segmentation = [0 if i < 0 else i for i in segmentation]\n",
        "        polygons.append(segmentation)\n",
        "    return polygons\n",
        "\n",
        "\n",
        "def create_image_info(image_id, file_name, image_size, date_captured=datetime.datetime.utcnow().isoformat(' '),\n",
        "                      license_id=1, coco_url=\"\", flickr_url=\"\"):\n",
        "    return {\n",
        "        \"id\": image_id,\n",
        "        \"file_name\": file_name,\n",
        "        \"width\": image_size[0],\n",
        "        \"height\": image_size[1],\n",
        "        \"date_captured\": date_captured,\n",
        "        \"license\": license_id,\n",
        "        \"coco_url\": coco_url,\n",
        "        \"flickr_url\": flickr_url\n",
        "    }\n",
        "\n",
        "def create_annotation_info(annotation_id, image_id, category_info, binary_mask, tolerance=2):\n",
        "    binary_mask_encoded = coco_mask.encode(np.asfortranarray(binary_mask.astype(np.uint8)))\n",
        "    area = coco_mask.area(binary_mask_encoded)\n",
        "    if area < 1:\n",
        "        return None\n",
        "    bounding_box = coco_mask.toBbox(binary_mask_encoded)\n",
        "    segmentation = binary_mask_to_polygon(binary_mask, tolerance)\n",
        "    if not segmentation:\n",
        "        return None\n",
        "    return {\n",
        "        \"id\": annotation_id,\n",
        "        \"image_id\": image_id,\n",
        "        \"category_id\": category_info[\"id\"],\n",
        "        \"iscrowd\": category_info[\"is_crowd\"],\n",
        "        \"area\": float(area),\n",
        "        \"bbox\": bounding_box.tolist(),\n",
        "        \"segmentation\": segmentation,\n",
        "        \"width\": binary_mask.shape[1],\n",
        "        \"height\": binary_mask.shape[0]\n",
        "    }\n",
        "\n",
        "# Initialize COCO dataset structure\n",
        "coco_output = {\n",
        "    \"info\": {},\n",
        "    \"licenses\": [],\n",
        "    \"images\": [],\n",
        "    \"annotations\": [],\n",
        "    \"categories\": [{\"id\": 0, \"name\": \"water_body\", \"supercategory\": \"water_body\"}]\n",
        "}\n",
        "\n",
        "image_id = 1\n",
        "annotation_id = 1\n",
        "\n",
        "# Read images and masks\n",
        "# Read images and masks\n",
        "for img_file in sorted(os.listdir(images_path), key=natural_key):\n",
        "    if img_file.endswith('.jpg'):\n",
        "        mask_file = img_file  # Use the same file name for mask as the image\n",
        "        image_path = os.path.join(images_path, img_file)\n",
        "        mask_path = os.path.join(masks_path, mask_file)\n",
        "\n",
        "        # Load image and mask\n",
        "        image = imread(image_path)\n",
        "        mask = imread(mask_path) > 128  # Directly load JPG mask and apply threshold\n",
        "\n",
        "        # Create COCO data\n",
        "        image_info = create_image_info(image_id, img_file, image.shape)\n",
        "        annotation_info = create_annotation_info(annotation_id, image_id, {\"id\": 0, \"is_crowd\": 0}, mask)\n",
        "\n",
        "        if annotation_info:\n",
        "            coco_output[\"images\"].append(image_info)\n",
        "            coco_output[\"annotations\"].append(annotation_info)\n",
        "            image_id += 1\n",
        "            annotation_id += 1\n",
        "\n",
        "# Save to JSON\n",
        "with open('coco_dataset.json', 'w') as outfile:\n",
        "    json.dump(coco_output, outfile, indent=4)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfFd5PPDv1hx"
      },
      "source": [
        "## 2. Create a train/test split for the annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOfPunl2iW9r"
      },
      "outputs": [],
      "source": [
        "\n",
        "#install funcy for the script below\n",
        "!pip install funcy\n",
        "\n",
        "\n",
        "!pip install scikit-multilearn\n",
        "\n",
        "\n",
        "\n",
        "#from: https://github.com/akarazniewicz/cocosplit/blob/master/cocosplit.py\n",
        "\n",
        "#!python /content/drive/MyDrive/Project/Kaggle/split_coco_annotations.py /content/drive/MyDrive/Project/Kaggle/Water\\ bodies\\ resized/annotations.json /content/drive/MyDrive/Project/Kaggle/Water\\ bodies\\ resized/train_annotations.json /content/drive/MyDrive/Project/Kaggle/Water\\ bodies\\ resized/test_annotations.json -s 0.8 --having-annotations --multi-class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjDTSYhGpury"
      },
      "outputs": [],
      "source": [
        "images_path = \"/content/drive/MyDrive/Project/Kaggle/Water bodies resized/images/\"\n",
        "mask_path = \"/content/drive/MyDrive/Project/Kaggle/Water bodies resized/masks/\"\n",
        "\n",
        "\n",
        "def create_train_test_split(annotations_path, train_ratio=0.8):\n",
        "    # Load annotations\n",
        "    with open(annotations_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Shuffle images\n",
        "    images = data['images']\n",
        "    np.random.shuffle(images)\n",
        "\n",
        "    # Split into train and test\n",
        "    num_train = int(len(images) * train_ratio)\n",
        "    train_images = images[:num_train]\n",
        "    test_images = images[num_train:]\n",
        "\n",
        "    # Function to filter annotations based on image ids\n",
        "    def filter_annotations(images, annotations):\n",
        "        image_ids = {image['id'] for image in images}\n",
        "        return [anno for anno in annotations if anno['image_id'] in image_ids]\n",
        "\n",
        "    # Split annotations\n",
        "    train_annotations = filter_annotations(train_images, data['annotations'])\n",
        "    test_annotations = filter_annotations(test_images, data['annotations'])\n",
        "\n",
        "    # Create train and test datasets\n",
        "    train_dataset = {'images': train_images, 'annotations': train_annotations, 'categories': data['categories']}\n",
        "    test_dataset = {'images': test_images, 'annotations': test_annotations, 'categories': data['categories']}\n",
        "\n",
        "    # Save new annotation files\n",
        "    train_annotations_path = os.path.join(os.path.dirname(annotations_path), 'annotations_train.json')\n",
        "    test_annotations_path = os.path.join(os.path.dirname(annotations_path), 'annotations_test.json')\n",
        "\n",
        "    with open(train_annotations_path, 'w') as f:\n",
        "        json.dump(train_dataset, f)\n",
        "    with open(test_annotations_path, 'w') as f:\n",
        "        json.dump(test_dataset, f)\n",
        "\n",
        "    return train_annotations_path, test_annotations_path\n",
        "\n",
        "# Example usage\n",
        "annotations_path = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/coco_dataset.json'\n",
        "train_annotations_path, test_annotations_path = create_train_test_split(annotations_path)\n",
        "print(\"Train annotations saved to:\", train_annotations_path)\n",
        "print(\"Test annotations saved to:\", test_annotations_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8wH2P6d8j0N"
      },
      "source": [
        "## 3. Register the dataset for use on the Detectron 2 dataset\n",
        "### Adapting tutorial on the Detectron2 Github:\n",
        "### https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html\n",
        "### https://colab.research.google.com/drive16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=tVJoOm6LVJwW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlNIHcJI9GaW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def get_waterbodies_dicts(img_dir, annotations_json):\n",
        "    json_file = os.path.join(img_dir, annotations_json)\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for idx, v in enumerate(imgs_anns['images']):\n",
        "        record = {}\n",
        "        filename = os.path.join(img_dir, v['file_name'])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "\n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        annos = [anno for anno in imgs_anns['annotations'] if anno['image_id'] == v['id']]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            obj = {\n",
        "                \"bbox\": anno['bbox'],\n",
        "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                \"segmentation\": anno['segmentation'],\n",
        "                \"category_id\": anno['category_id'],\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# Paths to the train and test annotation files\n",
        "train_annotations_path = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/annotations_train.json'\n",
        "test_annotations_path = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/annotations_test.json'\n",
        "\n",
        "# Register the datasets\n",
        "DatasetCatalog.register(\"waterbodies_train\", lambda: get_waterbodies_dicts(\"/content/drive/MyDrive/Project/Kaggle/Water bodies resized/images/\", train_annotations_path))\n",
        "MetadataCatalog.get(\"waterbodies_train\").set(thing_classes=[\"waterbody\"])\n",
        "\n",
        "DatasetCatalog.register(\"waterbodies_test\", lambda: get_waterbodies_dicts(\"/content/drive/MyDrive/Project/Kaggle/Water bodies resized/images/\", test_annotations_path))\n",
        "MetadataCatalog.get(\"waterbodies_test\").set(thing_classes=[\"waterbody\"])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4us7raCOn60"
      },
      "outputs": [],
      "source": [
        "#get the datacatalog to verify that the dataset has been registered correctly\n",
        "\n",
        "nuts_metadata = MetadataCatalog.get('waterbodies_train')\n",
        "dataset_dicts = DatasetCatalog.get(\"waterbodies_train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adNCwHEwcfjp"
      },
      "source": [
        "## 4. Configure model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YEr5MJXlOoEp"
      },
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "import detectron2.data.transforms as T\n",
        "\n",
        "\n",
        "#FROM: https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5#scrollTo=7unkuuiqLdqd\n",
        "\n",
        "#Defaults: https://github.com/facebookresearch/detectron2/blob/main/detectron2/config/defaults.py\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"waterbodies_train\",)\n",
        "#maybe remove the test function as no evaluator is set. AND you will evaluate later\n",
        "cfg.DATASETS.TEST = (\"waterbodies_test\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Initialize from model zoo weights\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "#cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MAX_ITER = 20000    # I may need to adjust this based on dataset size and desired training time.\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Do I need to update this based on class size?\n",
        "\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (512,)  # Only one size, no choice needed\n",
        "cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"  # 'choice' is fine here as there's only one option\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 512  # No need to allow any larger sizes\n",
        "cfg.INPUT.MIN_SIZE_TEST = 512  # Same as training\n",
        "cfg.INPUT.MAX_SIZE_TEST = 512  # Same as training\n",
        "\n",
        "\n",
        "#SHOW CONFIGURATION\n",
        "#cfg.display()????????????????\n",
        "\n",
        "#cfg.SOLVER.STEPS = [15000, 35000]  # Efor 50,000\n",
        "\n",
        "#cfg.SOLVER.STEPS = [5000, 15000]\n",
        "\n",
        "\n",
        "\n",
        "#STEP 2 FINE TUNE\n",
        "\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/Project/MaskR_CNN_Modelv6/\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYJbmp56GND_"
      },
      "outputs": [],
      "source": [
        "#check that GPU is connected\n",
        "if torch.cuda.is_available:\n",
        "  print('GPU available')\n",
        "else:\n",
        "  print('Please set GPU via Edit -> Notebook Settings.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcfes2GLcv6e"
      },
      "source": [
        "## 5. train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9UXMRoEcus-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg.VIS_PERIOD = 1\n",
        "\n",
        "\n",
        "# Initialize the trainer and start training\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WnJ3U2DkHqK"
      },
      "source": [
        "## 6. Evaluate!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rnjcAX6_kG4z"
      },
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "cfg = get_cfg()\n",
        "# Add model configuration settings (the same settings used during training)\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Threshold for confidence score\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Project/MaskR_CNN_Modelv6/model_final.pth\"  # Path to the model weights\n",
        "\n",
        "# adjust the number of classes based on dataset\n",
        "#cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
        "\n",
        "\n",
        "cfg.DATASETS.TEST = (\"waterbodies_test\",)\n",
        "\n",
        "val_loader = build_detection_test_loader(cfg, \"waterbodies_test\")\n",
        "evaluator = COCOEvaluator(\"waterbodies_test\", cfg, False, output_dir=\"/content/drive/MyDrive/Project/MaskR_CNN_Modelnoresize/output/\")\n",
        "\n",
        "\n",
        "# Set the threshold for this model\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "\n",
        "# Load the dataset and evaluator\n",
        "\n",
        "\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)  # Load the model weights\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this if loading model after deleting session"
      ],
      "metadata": {
        "id": "SUW_uNhtd0TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import build_detection_test_loader, MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "\n",
        "# Register the dataset only if it's not already registered\n",
        "dataset_name = \"waterbodies_test\"\n",
        "annotation_file = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/annotations_test.json'\n",
        "image_dir = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/images/'\n",
        "\n",
        "if dataset_name not in DatasetCatalog.list():\n",
        "    register_coco_instances(dataset_name, {}, annotation_file, image_dir)\n",
        "\n",
        "\n",
        "# Configuration for the model\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Project/MaskR_CNN_Modelv6/model_final.pth\"\n",
        "\n",
        "#cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Project/MaskR_CNN_Modelnoresize/model_final.pth\"\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.DATASETS.TEST = (\"waterbodies_test\",)\n",
        "cfg.DATASETS.TRAIN = (\"waterbodies_train\",)  # Make sure no default COCO dataset is referenced\n",
        "cfg.DATASETS.VAL = (\"waterbodies_test\",)  # Make sure no default COCO dataset is referenced\n",
        "# cfg.INPUT.MIN_SIZE_TRAIN = (512,)  # Only one size, no choice needed\n",
        "# cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
        "# cfg.INPUT.MAX_SIZE_TRAIN = 512  # No need to allow any larger sizes\n",
        "# cfg.INPUT.MIN_SIZE_TEST = 512  # Same as training\n",
        "# cfg.INPUT.MAX_SIZE_TEST = 512  # Same as training\n",
        "# Setting up the test data loader and evaluator\n",
        "val_loader = build_detection_test_loader(cfg, \"waterbodies_test\")\n",
        "evaluator = COCOEvaluator(\"waterbodies_test\", cfg, False, output_dir=\"/content/drive/MyDrive/Project/MaskR_CNN_Modelv6/output/\")\n",
        "\n",
        "# Load the model and evaluate\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=True)\n",
        "#results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "#print(results)"
      ],
      "metadata": {
        "id": "cA7Qz9hsPfW9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
<<<<<<< HEAD
        "## 7. Get predicted masks and pixel count"
=======
        "## 7. Fine Tune\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVlwd6LGdXf7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# cfg = get_cfg()\n",
        "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "# cfg.DATASETS.TRAIN = (\"waterbodies_train\",)\n",
        "# cfg.DATASETS.TEST = (\"waterbodies_test\",)\n",
        "# cfg.DATALOADER.NUM_WORKERS = 4\n",
        "# # dfsdf\n",
        "# # Load the last saved model\n",
        "# cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Project/MaskR_CNN_Modelnoresize/model_final.pth\"  # Update this path to your last checkpoint\n",
        "\n",
        "# cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "# cfg.SOLVER.BASE_LR = 0.0025  # New learning rate\n",
        "# cfg.SOLVER.MAX_ITER = 250000  # Total number of iterations including those already done in previous training\n",
        "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "\n",
        "# cfg.INPUT.MIN_SIZE_TRAIN = (512,)  # Only one size, no choice needed\n",
        "# cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"  # 'choice' is fine here as there's only one option\n",
        "# cfg.INPUT.MAX_SIZE_TRAIN = 512  # No need to allow any larger sizes\n",
        "# cfg.INPUT.MIN_SIZE_TEST = 512  # Same as training\n",
        "# cfg.INPUT.MAX_SIZE_TEST = 512  # Same as training\n",
        "\n",
        "# # Adjust the steps if you want to change the points at which the learning rate changes\n",
        "# cfg.SOLVER.STEPS = [150000, 180000]\n",
        "\n",
        "# cfg.SOLVER.RESUME = True  # Resume from the last checkpoint\n",
        "\n",
        "# # Set output directory\n",
        "# cfg.OUTPUT_DIR = \"/content/drive/MyDrive/Project/MaskR_CNN_Modelnoresize/\"\n",
        "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Get predicted masks and pixel count"
>>>>>>> 158534d6aaedb57b618a3942cff5ec0c915b0143
      ],
      "metadata": {
        "id": "UOhCIdg6S3HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "\n",
        "#Sources: https://stackoverflow.com/questions/64210521/compute-precision-and-accuracy-using-numpy\n",
        "# sources: https://github.com/facebookresearch/detectron2/issues/984\n",
        "#Sources: https://stackoverflow.com/questions/46689428/convert-np-array-of-type-float64-to-type-uint8-scaling-values\n",
        "#sources: https://stackoverflow.com/questions/60227833/how-to-filter-coco-dataset-classes-annotations-for-custom-dataset\n",
        "\n",
        "\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Define paths\n",
        "annotation_path = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/annotations_train.json'\n",
        "image_dir = '/content/drive/MyDrive/Project/Kaggle/Water bodies resized/images/'\n",
        "actual_masks_dir = '/content/drive/MyDrive/Project/MaskR_CNN_Modelv6/actual masks/'\n",
        "predicted_masks_dir = '/content/drive/MyDrive/Project/MaskR_CNN_Modelv6/predicted masks/'\n",
        "output_csv_path = '/content/drive/MyDrive/Project/MaskR_CNN_Modelv6/water_pixel_counts44.csv'\n",
        "\n",
        "# Create directories if they do not exist\n",
        "os.makedirs(actual_masks_dir, exist_ok=True)\n",
        "os.makedirs(predicted_masks_dir, exist_ok=True)\n",
        "\n",
        "# Load annotations\n",
        "with open(annotation_path) as f:\n",
        "    annotations = json.load(f)\n",
        "\n",
        "image_files = os.listdir(image_dir)\n",
        "results = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Could not read image {image_path}\")\n",
        "        continue\n",
        "    # Detectron2's DefaultPredictor expects images in BGR format (as read by OpenCV)\n",
        "\n",
        "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Use regex to find the last group of digits in the filename\n",
        "    image_id_matches = re.findall(r'(\\d+)(?!.*\\d)', image_file)\n",
        "    if image_id_matches:\n",
        "        image_id = int(image_id_matches[0])  # Get the last group of digits as the image ID\n",
        "    else:\n",
        "        print(f\"No image ID found in filename {image_file}\")\n",
        "        continue  # Skip files where no numeric ID is found\n",
        "\n",
        "    print(f\"Processing image_id: {image_id}\")\n",
        "\n",
        "    # Find all annotations for this image_id\n",
        "    ann_list = [ann for ann in annotations['annotations'] if ann['image_id'] == image_id]\n",
        "    if not ann_list:\n",
        "        print(f\"No annotation found for image_id {image_id}\")\n",
        "        continue\n",
        "\n",
        "    # Create the actual mask by combining all annotations for this image\n",
        "    mask_image = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    for ann in ann_list:\n",
        "        segmentation = ann['segmentation']\n",
        "        polygons = []\n",
        "        if isinstance(segmentation, list):\n",
        "            if isinstance(segmentation[0], list):\n",
        "                # Multiple polygons\n",
        "                for seg in segmentation:\n",
        "                    coords = np.array(seg).reshape(-1, 2)\n",
        "                    polygons.append(coords.astype(np.int32))\n",
        "            else:\n",
        "                # Single polygon\n",
        "                coords = np.array(segmentation).reshape(-1, 2)\n",
        "                polygons.append(coords.astype(np.int32))\n",
        "        else:\n",
        "            print(f\"Unknown segmentation format for image_id {image_id}\")\n",
        "            continue\n",
        "        # Fill the polygons on the mask\n",
        "        cv2.fillPoly(mask_image, polygons, 255)\n",
        "\n",
        "    actual_water_pixels = np.sum(mask_image == 255)\n",
        "\n",
        "    # Generate predictions\n",
        "    outputs = predictor(image)\n",
        "    pred_masks = outputs['instances'].pred_masks.cpu().numpy()\n",
        "    if pred_masks.size == 0:\n",
        "        predicted_mask = np.zeros_like(mask_image)\n",
        "    else:\n",
        "        predicted_mask = (np.sum(pred_masks, axis=0) >= 1).astype(np.uint8) * 255\n",
        "    predicted_water_pixels = np.sum(predicted_mask == 255)\n",
        "\n",
        "    # Convert masks to binary format (0 and 1)\n",
        "    actual_mask_binary = (mask_image == 255).astype(np.uint8)\n",
        "    predicted_mask_binary = (predicted_mask == 255).astype(np.uint8)\n",
        "\n",
        "    # Flatten the masks for calculation\n",
        "    actual_mask_flat = actual_mask_binary.flatten()\n",
        "    predicted_mask_flat = predicted_mask_binary.flatten()\n",
        "\n",
        "    # Calculate True Positives (TP), False Positives (FP), False Negatives (FN), True Negatives (TN)\n",
        "    TP = np.sum((actual_mask_flat == 1) & (predicted_mask_flat == 1))\n",
        "    FP = np.sum((actual_mask_flat == 0) & (predicted_mask_flat == 1))\n",
        "    FN = np.sum((actual_mask_flat == 1) & (predicted_mask_flat == 0))\n",
        "    TN = np.sum((actual_mask_flat == 0) & (predicted_mask_flat == 0))\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
        "\n",
        "    results.append({\n",
        "        'image_id': image_id,\n",
        "        'actual_water_pixels': actual_water_pixels,\n",
        "        'predicted_water_pixels': predicted_water_pixels,\n",
        "        'TP': TP,\n",
        "        'FP': FP,\n",
        "        'FN': FN,\n",
        "        'TN': TN,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score,\n",
        "        'iou': iou\n",
        "    })\n",
        "\n",
        "    # Save mask images to specified directories\n",
        "    actual_mask_path = os.path.join(actual_masks_dir, f'actual_mask_{image_id}.png')\n",
        "    predicted_mask_path = os.path.join(predicted_masks_dir, f'predicted_mask_{image_id}.png')\n",
        "    cv2.imwrite(actual_mask_path, mask_image)\n",
        "    cv2.imwrite(predicted_mask_path, predicted_mask)\n",
        "\n",
        "# Save results to CSV\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "print(df)\n",
        "\n",
        "# Ocalculate and print average metrics over all images\n",
        "average_metrics = df[['precision', 'recall', 'f1_score', 'iou']].mean()\n",
        "print(\"\\nAverage metrics over all images:\")\n",
        "print(average_metrics)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "x_zMZDrFcG2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Test on video"
      ],
      "metadata": {
        "id": "he-680bSShLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Taken from https://stackoverflow.com/questions/60663073/how-can-i-properly-run-detectron2-on-videos\n",
        "\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "# import libraries\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import cv2\n",
        "# import detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.video_visualizer import VideoVisualizer\n",
        "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "import time\n",
        "\n",
        "# Extract video properties\n",
        "video = cv2.VideoCapture('/content/drive/MyDrive/Project/Google Timelapse/Mareb3.mp4')\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Initialize video writer\n",
        "video_writer = cv2.VideoWriter('/content/drive/MyDrive/Project/Google Timelapse/mareb3out.mp4', fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"), fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n",
        "\n",
        "# Initialize predictor\n",
        "#cfg = get_cfg()\n",
        "#cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "#cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1  # set threshold for this model\n",
        "#cfg.MODEL.WEIGHTS = os.path.join(\"/content/drive/MyDrive/Project/MaskR_CNN_Modelv6\", \"model_final.pth\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Initialize visualizer\n",
        "v = VideoVisualizer(MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), ColorMode.IMAGE)\n",
        "\n",
        "def runOnVideo(video, maxFrames):\n",
        "    \"\"\" Runs the predictor on every frame in the video (unless maxFrames is given),\n",
        "    and returns the frame with the predictions drawn.\n",
        "    \"\"\"\n",
        "\n",
        "    readFrames = 0\n",
        "    while True:\n",
        "        hasFrame, frame = video.read()\n",
        "        if not hasFrame:\n",
        "            break\n",
        "\n",
        "        # Get prediction results for this frame\n",
        "        outputs = predictor(frame)\n",
        "\n",
        "        # Make sure the frame is colored\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Draw a visualization of the predictions using the video visualizer\n",
        "        visualization = v.draw_instance_predictions(frame, outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "        # Convert Matplotlib RGB format to OpenCV BGR format\n",
        "        visualization = cv2.cvtColor(visualization.get_image(), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        yield visualization\n",
        "\n",
        "        readFrames += 1\n",
        "        if readFrames > maxFrames:\n",
        "            break\n",
        "\n",
        "# Create a cut-off for debugging\n",
        "num_frames = 120\n",
        "\n",
        "# Enumerate the frames of the video\n",
        "for visualization in tqdm.tqdm(runOnVideo(video, num_frames), total=num_frames):\n",
        "\n",
        "    # Write test image\n",
        "    cv2.imwrite('/content/drive/MyDrive/Project/Google Timelapse/POSE detectron2.png', visualization)\n",
        "\n",
        "    # Write to video file\n",
        "    video_writer.write(visualization)\n",
        "\n",
        "# Release resources\n",
        "video.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "f_ZQA6RpRjQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}