{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8S0WjJ4s_BdC"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Install Detectron2 from the source\n",
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "OVIaq_d7_Pv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF4s-2sgu1fs"
      },
      "outputs": [],
      "source": [
        "#Set up directory and mounting from GDrive\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.structures import BoxMode\n"
      ],
      "metadata": {
        "id": "tkM4-fcj_SwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the model"
      ],
      "metadata": {
        "id": "KAZ2lrCEP1i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import build_detection_test_loader, MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "# Register the dataset only if it's not already registered\n",
        "#dataset_name = \"waterbodies_test\"\n",
        "\n",
        "\n",
        "def get_waterbodies_dicts(img_dir, annotations_json):\n",
        "    json_file = os.path.join(img_dir, annotations_json)\n",
        "    with open(json_file) as f:\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    dataset_dicts = []\n",
        "    for idx, v in enumerate(imgs_anns['images']):\n",
        "        record = {}\n",
        "        filename = os.path.join(img_dir, v['file_name'])\n",
        "        height, width = cv2.imread(filename).shape[:2]\n",
        "\n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        annos = [anno for anno in imgs_anns['annotations'] if anno['image_id'] == v['id']]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            obj = {\n",
        "                \"bbox\": anno['bbox'],\n",
        "                \"bbox_mode\": BoxMode.XYWH_ABS,\n",
        "                \"segmentation\": anno['segmentation'],\n",
        "                \"category_id\": anno['category_id'],\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# Paths to the train and test annotation files\n",
        "\n",
        "# Register the datasets\n",
        "# Paths to the train and test annotation files\n",
        "annotation_file_test = '/content/drive/MyDrive/Project/annotations_test.json'\n",
        "annotation_file_train = '/content/drive/MyDrive/Project/annotations_train.json'\n",
        "\n",
        "# Register the datasets\n",
        "DatasetCatalog.register(\"waterbodies_train\", lambda: get_waterbodies_dicts(\"/content/drive/MyDrive/Project/images/\", annotation_file_train))\n",
        "MetadataCatalog.get(\"waterbodies_train\").set(thing_classes=[\"waterbody\"])\n",
        "\n",
        "DatasetCatalog.register(\"waterbodies_test\", lambda: get_waterbodies_dicts(\"/content/drive/MyDrive/Project/images/\", annotation_file_test))\n",
        "MetadataCatalog.get(\"waterbodies_test\").set(thing_classes=[\"waterbody\"])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CTVHk0LLP0ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = \"/content/drive/MyDrive/Project/model_final.pth\"\n",
        "\n",
        "#threshold for predictions\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.DATASETS.TEST = (\"waterbodies_test\",)\n",
        "cfg.DATASETS.TRAIN = (\"waterbodies_train\",)  # Make sure no default COCO dataset is referenced\n",
        "cfg.DATASETS.VAL = (\"waterbodies_test\",)  # Make sure no default COCO dataset is referenced\n",
        "# cfg.INPUT.MIN_SIZE_TRAIN = (512,)  # Only one size, no choice needed\n",
        "# cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = \"choice\"\n",
        "# cfg.INPUT.MAX_SIZE_TRAIN = 512  # No need to allow any larger sizes\n",
        "# cfg.INPUT.MIN_SIZE_TEST = 512  # Same as training\n",
        "# cfg.INPUT.MAX_SIZE_TEST = 512  # Same as training\n",
        "# Setting up the test data loader and evaluator\n",
        "val_loader = build_detection_test_loader(cfg, \"waterbodies_test\")\n",
        "evaluator = COCOEvaluator(\"waterbodies_test\", cfg, False, output_dir=\"/content/drive/MyDrive/Project/output/\")\n",
        "\n",
        "\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=True)\n",
        "# results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
        "# print(results)\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "xrEk1YOwd743"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install Google Earth Engine API\n",
        "!pip install earthengine-api"
      ],
      "metadata": {
        "id": "rKphDGy7w6Df",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project = 'southern-bonsai-435419-q2')"
      ],
      "metadata": {
        "id": "JA1rETJSw7HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set the Parameters for the outputs"
      ],
      "metadata": {
        "id": "4kSP51Z8UyYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Set Area and buffer zone\n",
        "#Mareb\n",
        "longitude = 45.230503\n",
        "latitude = 15.376969\n",
        "bufferzone = 2500\n",
        "descrip = 'Mareb_dam_landsat'\n",
        "#Mareb\n",
        "# longitude = 45.230503\n",
        "# latitude = 15.376969\n",
        "# bufferzone = 3000\n",
        "# descrip = 'Mareb_dam_sentinel'\n",
        "\n",
        "#Set parameters for satellite images\n",
        "# Date range if landsat\n",
        "start_date = '1984-01-01'\n",
        "end_date = '2022-12-31'\n",
        "date_range = '1984-2022'\n",
        "\n",
        "\n",
        "\n",
        "#Wadi Wajar Abyan\n",
        "# longitude = 46.156746\n",
        "# latitude = 13.941848\n",
        "# bufferzone = 2500\n",
        "# descrip = 'Wadi_wajar_landsat'\n",
        "\n",
        "#Bani Matar Sana'a\n",
        "# longitude = 43.994586\n",
        "# latitude = 15.203803\n",
        "# bufferzone = 800\n",
        "# descrip = 'Bani_matar_landsat'\n",
        "\n",
        "#Wadi Wajar Abyan\n",
        "# longitude = 46.156746\n",
        "# latitude = 13.941848\n",
        "# bufferzone = 1000\n",
        "#descrip = 'Wadi_wajar_sentinel'\n",
        "\n",
        "#if sentinel\n",
        "# start_date = '2016-01-01'  # Sentinel-2 operation start\n",
        "# end_date = '2022-12-31'\n",
        "# date_range = '2016-2022'\n",
        "# descrip = 'Mareb_dam_sentinel'\n"
      ],
      "metadata": {
        "id": "qKR_Wghpkhir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Landsat Images"
      ],
      "metadata": {
        "id": "Fp6O4v3m7-he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import time\n",
        "#adapted from https://github.com/csaybar/EEwPython/blob/master/10_Export.ipynb\n",
        "# Initialize the Earth Engine API\n",
        "ee.Initialize()\n",
        "\n",
        "\n",
        "\n",
        "point = ee.Geometry.Point([longitude, latitude])\n",
        "buffered_point = point.buffer(bufferzone)\n",
        "region = buffered_point.bounds()\n",
        "\n",
        "# Load and merge the updated image collections using Collection 2 data\n",
        "landsat5 = ee.ImageCollection('LANDSAT/LT05/C02/T1_TOA').filterDate('1984-01-01', '2012-05-05')\n",
        "landsat7 = ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA').filterDate('1999-01-01', '2022-12-31')\n",
        "landsat8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA').filterDate('2013-01-01', '2022-12-31')\n",
        "full_collection = landsat5.merge(landsat7).merge(landsat8)\n",
        "\n",
        "# Filter out images with more than 10% cloud cover and within the region\n",
        "filtered_collection = full_collection.filter(ee.Filter.lt('CLOUD_COVER', 10)).filterBounds(region).select(['B4', 'B3', 'B2'])\n",
        "\n",
        "# Generate a list of months between the start and end dates\n",
        "start = ee.Date(start_date)\n",
        "end = ee.Date(end_date)\n",
        "n_months = end.difference(start, 'month').round()\n",
        "months = ee.List.sequence(0, n_months.subtract(1)).map(lambda n: start.advance(n, 'month'))\n",
        "\n",
        "# Function to get one image per month\n",
        "def get_image_for_month(month):\n",
        "    month = ee.Date(month)\n",
        "    month_end = month.advance(1, 'month')\n",
        "    # Filter images in the month\n",
        "    images_in_month = filtered_collection.filterDate(month, month_end)\n",
        "    # Get the first image\n",
        "    image = ee.Image(images_in_month.first())\n",
        "    # Check if image exists\n",
        "    return ee.Algorithms.If(image, image.set('system:time_start', month.millis()), None)\n",
        "\n",
        "# Map the function over the list of months to create a list of images\n",
        "images_list = months.map(get_image_for_month)\n",
        "\n",
        "# Create an ImageCollection from the list of images and filter out None values\n",
        "monthly_images = ee.ImageCollection.fromImages(images_list).filter(ee.Filter.notNull(['system:time_start']))\n",
        "\n",
        "# Function to scale and cast images\n",
        "def scale_and_cast(image):\n",
        "    return image.multiply(255).byte()  # Scale and convert to uint8\n",
        "\n",
        "# Apply the function to each image in the collection\n",
        "monthly_images = monthly_images.map(scale_and_cast)\n",
        "\n",
        "\n",
        "\n",
        "# Create and start the video export task\n",
        "task = ee.batch.Export.video.toDrive(\n",
        "    collection=monthly_images,\n",
        "    description=descrip,\n",
        "    dimensions=1080,\n",
        "    framesPerSecond=12,\n",
        "    region=region.coordinates().getInfo(),\n",
        "    folder='videosIn2',\n",
        "    maxPixels=1e13,\n",
        "    maxFrames=10000  # Increase the maxFrames as needed\n",
        ")\n",
        "task.start()\n",
        "\n",
        "# Monitor the task\n",
        "while task.active():\n",
        "    print('Polling for task (id: {}).'.format(task.id))\n",
        "    time.sleep(10)  # Sleep for 10 seconds before polling again\n",
        "\n",
        "print(\"Video export complete.\")\n"
      ],
      "metadata": {
        "id": "L_3gRiSS4rDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentinel-2 images"
      ],
      "metadata": {
        "id": "RIfC5bHXf2jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import time\n",
        "\n",
        "# Initialize the Earth Engine API\n",
        "ee.Initialize()\n",
        "\n",
        "# Define the geographic location and buffer\n",
        "# longitude = 46.156746\n",
        "# latitude = 13.941848\n",
        "\n",
        "# video_name = 'Abyan3_Sentinel2'\n",
        "\n",
        "point = ee.Geometry.Point([longitude, latitude])\n",
        "buffered_point = point.buffer(bufferzone).bounds()  # Define a 2km buffer around the point\n",
        "region = buffered_point.bounds()\n",
        "\n",
        "# Date range\n",
        "# start_date = '2015-06-23'  # Sentinel-2 operation start\n",
        "# end_date = '2022-12-31'\n",
        "\n",
        "# Load Sentinel-2 ImageCollection\n",
        "collection = ee.ImageCollection('COPERNICUS/S2') \\\n",
        "    .filterDate(start_date, end_date) \\\n",
        "    .filterBounds(region) \\\n",
        "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))  # Filter images based on cloud cover\n",
        "\n",
        "# Select the RGB bands and scale\n",
        "def prepare_image(image):\n",
        "    return image.visualize(bands=['B4', 'B3', 'B2'], max=3000).clip(region)\n",
        "\n",
        "# Apply the function to each image in the collection\n",
        "prepared_collection = collection.map(prepare_image)\n",
        "\n",
        "# Create and start the video export task\n",
        "task = ee.batch.Export.video.toDrive(**{\n",
        "    'collection': prepared_collection,\n",
        "    'description': descrip,\n",
        "    'dimensions': 1080,\n",
        "    'framesPerSecond': 12,\n",
        "    'region': region.coordinates().getInfo(),\n",
        "    'folder': 'VideosIn2',\n",
        "    'maxFrames': 10000\n",
        "})\n",
        "task.start()\n",
        "\n",
        "# Monitor the task\n",
        "while task.active():\n",
        "    print('Polling for task (id: {})'.format(task.id))\n",
        "    time.sleep(10)  # Sleep for 10 seconds before polling again\n",
        "\n",
        "print(\"Video export complete.\")"
      ],
      "metadata": {
        "id": "1756MVrvf7xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing exported video from GDrive and deploying predictor"
      ],
      "metadata": {
        "id": "t5d0oUhT_9pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapted from https://stackoverflow.com/questions/60663073/how-can-i-properly-run-detectron2-on-videos\n",
        "\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "# Import detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.video_visualizer import VideoVisualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "\n",
        "# Extract video properties\n",
        "descrip = descrip  # Set video description/name\n",
        "video_path = '/content/drive/MyDrive/VideosIn2/' + descrip + '.mp4'\n",
        "video = cv2.VideoCapture(video_path)\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = video.get(cv2.CAP_PROP_FPS)\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Initialize video writer\n",
        "output_video_path = '/content/drive/MyDrive/VideosOut2/' + descrip + '_out.mp4'\n",
        "video_writer = cv2.VideoWriter(\n",
        "    output_video_path,\n",
        "    fourcc=cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "    fps=float(frames_per_second),\n",
        "    frameSize=(width, height),\n",
        "    isColor=True,\n",
        ")\n",
        "\n",
        "# Initialize visualizer\n",
        "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
        "v = VideoVisualizer(metadata, ColorMode.IMAGE)\n",
        "\n",
        "# Define start date and generate list of dates for each frame\n",
        "# Define start and end years\n",
        "start_year = 2016\n",
        "end_year = 2022\n",
        "num_years = end_year - start_year + 1  # Inclusive of both start and end years\n",
        "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "frames_per_year = num_frames / num_years\n",
        "\n",
        "def runOnVideo(video, maxFrames):\n",
        "    \"\"\"Runs the predictor on every frame in the video (up to maxFrames),\n",
        "    and yields the frame index, frame, visualization, predicted mask, and predicted water pixel count.\n",
        "    \"\"\"\n",
        "    readFrames = 0\n",
        "    while True:\n",
        "        hasFrame, frame = video.read()\n",
        "        if not hasFrame:\n",
        "            break\n",
        "\n",
        "        # Get prediction results for this frame\n",
        "        outputs = predictor(frame)\n",
        "\n",
        "        # Get predicted masks\n",
        "        pred_masks = outputs['instances'].pred_masks.cpu().numpy()\n",
        "        if pred_masks.size == 0:\n",
        "            predicted_mask = np.zeros((frame.shape[0], frame.shape[1]), dtype=np.uint8)\n",
        "        else:\n",
        "            predicted_mask = (np.sum(pred_masks, axis=0) >= 1).astype(np.uint8) * 255\n",
        "\n",
        "        # Count the number of pixels in the predicted mask\n",
        "        predicted_water_pixels = np.sum(predicted_mask == 255)\n",
        "\n",
        "        # Draw a visualization of the predictions using the video visualizer\n",
        "        visualization = v.draw_instance_predictions(frame, outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "        # Convert Matplotlib RGB format to OpenCV BGR format\n",
        "        visualization = cv2.cvtColor(visualization.get_image(), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        yield readFrames, frame, visualization, predicted_mask, predicted_water_pixels\n",
        "\n",
        "        readFrames += 1\n",
        "        if readFrames >= maxFrames:\n",
        "            break\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Enumerate the frames of the video\n",
        "for frame_idx, frame, visualization, predicted_mask, predicted_water_pixels in tqdm.tqdm(\n",
        "    runOnVideo(video, num_frames), total=num_frames\n",
        "):\n",
        "    # Map frame indices to years\n",
        "    year = start_year + int(frame_idx * num_years / num_frames)\n",
        "    if year > end_year:\n",
        "        year = end_year  # Ensure the year does not exceed the end year\n",
        "\n",
        "    # Save images for specific years\n",
        "    if year in [2016, 2017, 2018, 2019, 2020,2021, 2022]:\n",
        "        # Save original frame\n",
        "        cv2.imwrite(f'/content/drive/MyDrive/VideosOut2/Images/{descrip}_original_{year}.png', frame)\n",
        "        # Save annotated frame\n",
        "        cv2.imwrite(f'/content/drive/MyDrive/VideosOut2/Images/{descrip}_annotated_{year}.png', visualization)\n",
        "        # Save mask frame\n",
        "        cv2.imwrite(f'/content/drive/MyDrive/VideosOut2/Images/{descrip}_mask_{year}.png', predicted_mask)\n",
        "\n",
        "    # Write to video file\n",
        "    video_writer.write(visualization)\n",
        "\n",
        "    # Collect results\n",
        "    results.append({'year': year, 'predicted_water_pixels': predicted_water_pixels})\n",
        "\n",
        "# Release resources\n",
        "video.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Create a dataframe from the results and save to CSV\n",
        "df = pd.DataFrame(results)\n",
        "csv_output_path = '/content/drive/MyDrive/VideosOut2/Data/predicted_water_pixel_counts_' + descrip + '.csv'\n",
        "df.to_csv(csv_output_path, index=False)\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "BzVeyeQTRzq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## visualise the change over time in terms of predicted pixels"
      ],
      "metadata": {
        "id": "tNQcBK4N3Gcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/VideosOut2/Data/predicted_water_pixel_counts_' + descrip + '.csv')\n",
        "\n",
        "# Group the data by year and calculate the average\n",
        "df_grouped = df.groupby('year')['predicted_water_pixels'].mean().reset_index()\n",
        "\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df_grouped['year'], df_grouped['predicted_water_pixels'])\n",
        "plt.title('Predicted Water Pixels Over Years (' + descrip + ')')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average Predicted Water Pixels')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot as a JPEG\n",
        "plt.savefig('/content/drive/MyDrive/VideosOut2/Plots/predicted_water_pixel_counts_' + descrip + '_aggregated.jpg', format='jpg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xlj4_5TyY3Tn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}